{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\"> THEME 4 - Donn√©es tabulaires </h1>\n",
    "\n",
    "### üéØ Objectifs\n",
    "\n",
    "- Manipuler des donn√©es tabulaires\n",
    "- Effectuer de l'analyse statistique\n",
    "\n",
    "### üìö Notions \n",
    "\n",
    "- [Exemple 1](#ex1):\n",
    "    - Cr√©er un Dataframe √† partir d'un dictionnaire\n",
    "    - Indexer des donn√©es\n",
    "    - Filtrer les donn√©es par masque binaire\n",
    "    - Trier des colonnes num√©riques\n",
    "- [Exemple 2](#ex2):\n",
    "    - Ouvrir un fichier de donn√©es (CSV, etc...) et cr√©er un Dataframe\n",
    "    - Groupy et aggregation de donn√©es\n",
    "    - Renommer des colonnes\n",
    "    - Filtrer des colonnes textuelles par mots cl√©s\n",
    "- [Exemple 3](#ex3):\n",
    "    - Retirer et remplacer des valeurs nulles\n",
    "    - Detecter et retirer des lignes dupliqu√©es\n",
    "    - Cr√©er un index √† partir d'une colonne\n",
    "    - Joindre deux Dataframes en fonction d'une cl√© commune\n",
    "\n",
    "Un [lexique](#lexique) avec l'ensemble des fonctions qui ont √©t√© vues est disponible √† la fin du notebook.\n",
    "\n",
    "### üß∞ Librairies\n",
    "\n",
    "- **Pandas**: est une librairie libre-source Python largement utilis√©e dans la science des donn√©es, l'analyse des donn√©es et l'apprentissage machine. Il est construit au-dessus de la librairie Numpy ce qui lui offre une interface similaire et permet l'interop√©rabilit√© avec des fonctions numpy.\n",
    "\n",
    "### üîó R√©f√©rence\n",
    "\n",
    "- [Documentation Polars](https://pola-rs.github.io/polars/py-polars/html/reference/)\n",
    "\n",
    "### ‚öôÔ∏è Installation\n",
    "\n",
    "`pip install pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex1\"><h2 align=\"center\"> Exemple 1 - Fleurs Iris </h2></a>\n",
    "\n",
    "### üìù Contexte\n",
    "\n",
    "L'Iris est un genre de plantes vivaces de la famille des Iridac√©es. Il existe une large vari√©t√© d'esp√®ces que l'on retrouve au Qu√©bec. L'Iris Versicolor est d'ailleur l'un des embl√®mes officiels du Quebec et se trouve le drapeau.\n",
    "\n",
    "<center> <img width=400px src=\"assets/iris.jpg\" /> </center>\n",
    "\n",
    "\n",
    "La fleur peut √™tre violette, bleue ou pourpre et plus rarement blanche. Elle est constitu√©e de trois p√©tales minces et relev√©s dispos√©s √† l'int√©rieur de la fleur et de trois s√©pales plus longs et plus larges en forme de spatule et situ√©s √† l'ext√©rieur. \n",
    "\n",
    "### ‚≠ê Objectif\n",
    "\n",
    "- Cr√©er un jeu de donn√©es √† partir d'un dictionnaire Python contenant les donn√©es de fleurs d'iris.\n",
    "- Indexer et filtrer les donn√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Code\n",
    "\n",
    "Un `DataFrame` est une structure de donn√©es tabulaires qui permet de stocker et manipuler des donn√©es de fa√ßon intuitive. Les donn√©es tabulaires sont organis√©es sous forme de lignes avec des colonnes communes. \n",
    "\n",
    "La fa√ßon la plus simple de cr√©er un `DataFrame` est de partir d'un objet Python. La nature de cet objet change en fonction du format des donn√©es:\n",
    "\n",
    "- Donn√©es colonnes: L'objet est un dictionnaire o√π les cl√©s sont les noms des colonnes, et o√π les valeurs sont des listes de m√™me taille qui vont constituer les colonnes. C'est le format qui sera utilis√© dans cet exemple.\n",
    "- Donn√©es lignes: L'objet est une liste de dictionnaires, o√π chaque dictionnaire ont les m√™mes cl√©s et poss√®de une seule valeur par cl√©.\n",
    "\n",
    "Ces deux formats sont interchangeables en fonction de l'application et ont chacun des forces et faiblesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "\n",
    "# Cr√©ation d'un DataFrame (df) √† partir d'un dict\n",
    "df_iris = pd.DataFrame(\n",
    "    {\n",
    "        \"Date\": pd.to_datetime(\"2022-06-15\"),  # Conversion d'un texte en date\n",
    "        \"Location\": \"Quebec\",  # Colonne location avec une valeur qui sera rep√©t√©e\n",
    "        \"Esp√®ce\": [\"Versicolor\", \"Versicolor\", \"Setosa\", \"Setosa\", \"Virginica\"],  # Liste python de mots\n",
    "        \"Petale_long\": [5.1, 4.7, 1.5, 1.6, 5.5],  # Liste python de nombres\n",
    "        \"Petale_larg\": np.array([1.2, 1.2, 0.2, 0.3, 2.1]),  # Numpy array\n",
    "    },\n",
    "    index=[\"fleur_0\", \"fleur_1\", \"fleur_2\", \"fleur_3\", \"fleur_4\"],\n",
    ")\n",
    "\n",
    "# Afficher le df\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le `DataFrame` cr√©√©, il est possible d'obtenir des informations sur ses colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_iris.shape)  # Forme du df (lignes, colonnes)\n",
    "print(df_iris.columns)  # Liste des colonnes du df\n",
    "print(df_iris.dtypes[\"Petale_long\"])  # Type de donn√©es d'une colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'indexation des donn√©es dans pandas est assez d√©licate puisqu'il existe 3 forme d'indexation:\n",
    "\n",
    "- Directe des colonnes: `df[<nom_colonne>]`. Utile pour selectionner **une seule** colonne et pour de la filtration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris[\"Esp√®ce\"]  # Selectionner une colonne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec `df.loc[<no_ligne>, <nom_colonne>]`. Utile pour selectionner **plusieurs** colonnes et lignes en m√™me temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[\"fleur_0\", \"Esp√®ce\"]  # Selectionner la premi√®re ligne de la colonne \"Esp√®ce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[\n",
    "    :, [\"Petale_long\", \"Petale_larg\"]\n",
    "]  # Selectionner toutes les lignes des colonnes \"Petale_long\" et \"Petale_larg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Avec `df.iloc[<no_ligne>, <no_colonne>]`. Similaire √† `.loc` mais utilise **uniquement** des indices num√©riques. Cette m√©thode est similaire √† l'indexation d'une matrice dans Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.iloc[0, -1]  # Selectionner la premi√®re ligne de la derni√®re colonne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.iloc[:3, -2:]  # Selectionner les 3 premi√®res lignes des 2 derni√®res colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise un `DataFrame` g√©n√©ralement lorsque l'on veut analyser un sous-ensemble de donn√©es avec une caract√©ristique particuli√®re. Cette caract√©ristique peut √™tre isol√©e en filtrant les donn√©es. L'une des m√©thodes est l'utilisation de masques binaires, similaires √† ceux employ√©s avec les Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtre = df_iris[\"Esp√®ce\"] == \"Setosa\"\n",
    "filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[filtre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prendre les iris avec une largeur de petale sup√©rieure √† 1 et une longueur de petale inf√©rieure √† 5.2, et selectionner\n",
    "# uniquement les colonnes  Esp√®ce, Petale_long et Petale_larg\n",
    "# Attention: ne pas oublier les parentheses entre chaque masque binaire\n",
    "filtre2 = (df_iris[\"Petale_larg\"] > 1) & (df_iris[\"Petale_long\"] < 5.2)\n",
    "df_iris.loc[filtre2, [\"Esp√®ce\", \"Petale_long\", \"Petale_larg\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise `.isin` pour isoler les lignes d'une colonne qui contient l'une des valeurs possibles d'une liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.loc[df_iris[\"Esp√®ce\"].isin([\"Setosa\", \"Virginica\"])]  # Selectionner les iris de type \"Setosa\" ou \"Versicolor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi trier les donn√©es avec une ou plusieurs colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier le tableau par les valeurs de la colonne \"Petale_long\" en ordre decroissant\n",
    "df_iris.sort_values(by=\"Petale_long\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier le tableau par les valeurs des colonnes \"Petale_long\" et \"Petale_larg\" en ordre croissant\n",
    "df_iris.sort_values(by=[\"Petale_long\", \"Petale_larg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que les op√©rations sont compl√©t√©s sur le `DataFrame`, il est simple de le convertir en dictionnaire avec la m√©thode `to_dict()` pour l'exporter par exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectionner les fleurs de type \"Setosa\" et \"Versicolor\" et les trier par ordre croissant de largeur de p√©tale\n",
    "new_df = df_iris[df_iris[\"Esp√®ce\"].isin([\"Setosa\", \"Versicolor\"])].sort_values(by=\"Petale_larg\")\n",
    "\n",
    "df_dict = new_df.to_dict(\"list\")  # \"List\" pour format colonne et \"records\" pour format ligne\n",
    "\n",
    "pp.pprint(df_dict)  # Afficher le dictionnaire r√©sultant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour des op√©rations matricielles, on peut aussi utiliser la m√©thode `to_numpy()` pour convertir des colonnes du DataFrame en matrice Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_petales = df_iris.loc[:, [\"Petale_long\", \"Petale_larg\"]].to_numpy()\n",
    "print(mat_petales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex2\"><h2 align=\"center\"> Exemple 2 - Transest√©rification du canola en biodiesel </h2></a>\n",
    "\n",
    "### üìù Contexte\n",
    "La transest√©rification est une m√©thode de production de biodiesel √† partir de la r√©action entre une huile v√©g√©tale et de l'alcool. Dans cet exemple, l'huile v√©g√©tale utilis√©e est le canola et la r√©action est la suivante:\n",
    "\n",
    "<center>\n",
    "<img width=500px src=\"assets/reaction_biodiesel.png\" />\n",
    "</center>\n",
    "\n",
    "Les triglyc√©rides du canola r√©agissent avec l'alcool et produisent du biodiesel et du glyc√©rol. Une chromatographie est effectu√©e √† la suite de la r√©action pour analyser son contenu chimique.\n",
    "\n",
    "<center>\n",
    "<img width=500px src=\"assets/chromato_biodiesel.png\" />\n",
    "</center>\n",
    "\n",
    "Enfin, une analyse num√©rique dans le logiciel de chromatographie permet d'extraire les donn√©es des pics les plus importants. \n",
    "\n",
    "### ‚≠ê Objectif\n",
    "\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Code\n",
    "\n",
    "Les donn√©es que l'on analyse sont d'habitude stock√©es sur un disque dans un fichier. Il existe une multitude de formats qui existent et les plus utilis√©s sont: `CSV`, `JSON`, `IPC`, `HDF5` et `Parquet`. \n",
    "\n",
    "Dans Pandas, il y a [plusieurs](https://pandas.pydata.org/docs/reference/io.html) fonctions qui permettent de ouvrir ces fichiers et les convertir facilement en `DataFrame`. \n",
    "\n",
    "Pour cet exemple, on utilise le format de base: `CSV`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier CSV avec un s√©parateur \";\"\n",
    "df_bio = pd.read_csv(\"assets/biodiesel.csv\", sep=\";\")\n",
    "\n",
    "df_bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la sience des donn√©es, l'un des outils fondamentaux est l'aggregation de donn√©es qui permet de regrouper les donn√©es appartenant √† un m√™me sous-groupe et en tirer plus facilement des r√©sultats num√©riques. \n",
    "\n",
    "Avec pandas, cela se fait avec la m√©thode `groupby` pour regrouper les donn√©es sur une ou plusieurs colonnes et `agg` pour sp√©cifier la m√©thode d'aggregation employ√©e, tr√®s souvent sur les donn√©es num√©riques. Apr√®s l'aggregation, il bonne pratique de renommer les colonnes pour mieux representer les nouvelles colonnes, avec pandas on peut faire cela avec la m√©thode `rename`.\n",
    "\n",
    "Les op√©rations d'aggregation possible sont:\n",
    "\n",
    "| Op√©ration        | Description              |\n",
    "| ---------------- | ------------------------ |\n",
    "| `mean`, `median` | Moyenne, M√©diane         |\n",
    "| `count`          | Nombre d'√©l√©ments        |\n",
    "| `first`, `last`  | Premier, Dernier √©l√©ment |\n",
    "| `std`, `var`     | Ecart-type, Variance     |\n",
    "| `min`, `max`     | Minimum, Maximum         |\n",
    "| `sum`, `prod`    | Somme, Produit           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes sont renomm√©es en utilisant un dictionnaire o√π les cl√©s sont les anciens noms et les valeurs sont\n",
    "# les nouveaux noms\n",
    "new_col = {\"Time\": \"Avg Time\", \"Area\": \"Total Area\"}\n",
    "\n",
    "# Manipulation du df\n",
    "# -------------------------------------------------\n",
    "# Les √©tapes peuvent √™tre √©galement √©crites sur une seule ligne\n",
    "df_new_bio = (\n",
    "    df_bio.groupby(\"Name\")  # Regrouper les lignes par \"Name\", mettre as_index=False est recommand√©\n",
    "    .agg({\"Time\": \"mean\", \"Area\": \"sum\"})  # Sp√©cifier l'op√©ration d'aggregation sur les colonnes non-regroup√©es\n",
    "    .rename(columns=new_col)  # Renommer les colonnes\n",
    ")\n",
    "\n",
    "df_new_bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir filtrer les lignes qui correspondent √† une mol√©cule de biodiesel, on peut utiliser `.str.contains(<crit√®re>)` sur une colonne ou un index de texte pour isoler les lignes qui contiennent un bout de texte. Dans notre cas, on remarque que les mol√©cules de biodiesel contiennent un \"C\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_bio.loc[df_new_bio.index.str.contains(\"C\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"ex3\"><h2 align=\"center\"> Exemple 3 - √âmissions √©coinvent </h2></a>\n",
    "\n",
    "\n",
    "### üìù Contexte\n",
    "\n",
    "Ecoinvent est une association √† but non lucratif qui met √† disposition des donn√©es de haute qualit√© reli√©es aux √©missions de divers proc√©d√©s industriels. √Ä partir de leur base de donn√©es, des donn√©es ont √©t√© extraites dans un fichier [parquet](https://en.wikipedia.org/wiki/Apache_Parquet) avec:\n",
    "\n",
    "- Le ID du proc√©d√©\n",
    "- Le nom de la particule √©mise\n",
    "- Le num√©ro CAS de cette particule\n",
    "- L'unit√© utilis√©e pour mesurer l'√©mission\n",
    "- Le milieu d'√©mission\n",
    "- Le sous-milieu d'√©mission \n",
    "\n",
    "√Ä partir de liste des num√©ros CAS uniques, les compositions chimiques de chaque mol√©cules ont √©t√© extraites dans un autre fichier parquet. Cette extraction a √©t√© possible grace aux librairies python open source: \n",
    "\n",
    "- [cirpy](https://github.com/mcs07/CIRpy) pour convertir le num√©ro CAS en repr√©sentation chimique.\n",
    "- [chempy](https://github.com/bjodah/chempy) pour obtenir les compositions chimiques. \n",
    "\n",
    "Ce fichier contient donc une colonne avec le num√©ro CAS et 118 colonnes pour chaque √©l√©ment atomique et sa quantit√© dans la mol√©cule.\n",
    "\n",
    "### ‚≠ê Objectif\n",
    "\n",
    "- Ouvrir ces fichiers xlsx comme `DataFrame`.\n",
    "- Rejoindre les deux tableaux grace au num√©ro CAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Code\n",
    "\n",
    "On commence par ouvrir les fichiers parquet en utilisant la m√©thode `read_parquet()` de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecoinvent = pd.read_parquet(\"assets/ecoinvent.parquet\")\n",
    "df_chempy = pd.read_parquet(\"assets/chempy.parquet\")\n",
    "\n",
    "df_ecoinvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 2)  # Pour une meilleure clart√©e on affiche le df avec 2 chiffres apr√®s la virgule\n",
    "\n",
    "df_chempy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le DataFrame `chempy` contient beaucoup de valeurs `NaN` qui correspondent √† des valeurs nulles. Il est tr√®s probable que certaines colonnes sont compl√®tement vide en raison de l'absence de cet √©l√©ment atomique dans la liste des particules, on peut donc retirer ces colonnes. \n",
    "\n",
    "Par la suite, pour √©viter d'avoir des erreurs lors d'un calcul de somme par exemple, il est pr√©f√©rable de remplacer les valeurs `NaN` par z√©ro.\n",
    "\n",
    "Pour une manipulation plus simple, la plupart des op√©rations sont effectu√©es `inplace=True` pour modifier le DataFrame directement sans cr√©er des copies inutiles. Cela est √©quivalent √† faire `df = df.<methode>`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes (axis=1) qui contiennent que des valeurs nulles (how=all)\n",
    "df_chempy.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "# Remplacer toutes les valeurs nulles par 0\n",
    "df_chempy.fillna(0, inplace=True)\n",
    "\n",
    "df_chempy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "G√©n√©ralement, lors de la manipulation de donn√©es tabulaire, il est souvent tr√®s possible d'√™tre en pr√©sence de lignes dupliqu√©es. On peut v√©rifier √ßa avec la m√©thode `.duplicated()` qui renvoie un masque binaire avec `True` pour les lignes dupliqu√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtre3 = df_chempy[\"CAS\"].duplicated()  # Trouver les lignes avec un CAS dupliqu√©\n",
    "df_chempy.loc[filtre3].sort_values(by=\"CAS\")  # Appliquer le filtre et trier par ordre croissant du CAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit donc qu'il y a 152 lignes qui sont des doublons. On peut les retirer du DataFrame avec la m√©thode `drop_duplicates()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chempy.drop_duplicates([\"CAS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la masse totale de la particule, on peut utiliser une fonction Lambda. Cette fonction permet d'√©valuer une expression math√©matique sur chaque ligne du DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter la table de la masse des √©l√©ments atomiques ??\n",
    "\n",
    "df_chempy[\"Masse Totale\"] = pd.Series(np.zeros(len(df_chempy)))\n",
    "df_chempy[\"Masse Totale\"] = df_chempy.loc[:, df_chempy.columns != \"CAS\"].sum(axis=1)\n",
    "\n",
    "df_chempy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rejoindre plusieurs tableaux de donn√©es est une autre op√©ration fondamentale dans la science des donn√©es. Pour des donn√©es de type relationnelles, comme celles que l'on a, des tableaux peuvent √™tre joints √† partir d'une ou plusieurs cl√©s communes entre les deux tables. Dans notre cas, la cl√© commune est le num√©ro CAS. \n",
    "\n",
    "Dans pandas, cette op√©ration se fait avec la m√©thode `.join()`. Il existe plusieurs types de join que l'on peut faire: `inner`, `outer`, `left` et `right`, une explication compl√®te avec des exemples est disponible [ici](https://learnsql.com/blog/sql-joins-types-explained/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avec Pandas, un join doit se faire entre 2 indexes avec le m√™me nom, il faut donc renommer la colonne CAS de df_chempy\n",
    "# et cr√©er un index pour les deux df.\n",
    "# -------------------------------------------------\n",
    "df_chempy.rename(columns={\"CAS\": \"cas\"}, inplace=True)\n",
    "df_chempy.set_index(\"cas\", inplace=True)\n",
    "df_ecoinvent.set_index(\"cas\", inplace=True)\n",
    "df_joined = df_ecoinvent.join(df_chempy, on=\"cas\", how=\"left\")\n",
    "\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat ?\n",
    "# pivot ?\n",
    "# query ?\n",
    "# reset index ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Astuces\n",
    "\n",
    "- Lors de la manpulation des `DataFrame`, par souci de performance, il est important de comprendre l'ordre des op√©rations qui sont effectu√©es. G√©n√©ralement, il faut commencer par tout filtrage des donn√©es et retirer les lignes ou colonnes que l'on veut exclure avant de faire une op√©ration math√©matique.\n",
    "- Dans la plupart des cas, les donn√©es utilis√©es d√©passent rarement le million de lignes. Cependant, dans le cas contraire, il faut commencer √† prendre en compte la taille des donn√©es et ce que √ßa implique en terme d'utilisation de la m√©moire. Tr√®s souvent cela consiste √† limiter le nombre de copies que l'on fait ainsi que adopter une structure de tableau plus compacte afin de diminuer sa taille. C'est un sujet un peu plus avanc√© mais tout de m√™me interessant √† savoir si on a l'intention de travailler avec du Big Data et construire des algorithmes qui roulent en temps r√©el par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"lexique\"><h2 align=\"center\"> Lexique </h2></a>\n",
    "\n",
    "### üìö Terminologie\n",
    "\n",
    "- `DataFrame` ou `df`: structure de donn√©es tabulaires en m√©moire qui permet de stocker et manipuler les colonnes et lignes de donn√©es.\n",
    "\n",
    "### ‚úîÔ∏è Vu dans l'exemple 1\n",
    "\n",
    "- `pd.DataFrame`: cr√©√© un DataFrame √† partir d'un objet Python comme une liste de dictionnaires ou un dictionnaire de listes.\n",
    "- `df.shape`: renvoie la taille du DataFrame.\n",
    "- `df.columns`: renvoie la liste des noms des colonnes.\n",
    "- `df.dtypes`: renvoie le type de donn√©es d'une colonne.\n",
    "- `df.loc`: indexation de plusieurs lignes et colonnes par noms et avec des masques binaires. \n",
    "- `df.iloc`: indexation par num√©ros de lignes et colonnes.\n",
    "- `df.isin`: masque binaire qui renvoie `True` pour les lignes qui contiennent une valeur dans une liste de valeurs possibles.\n",
    "- `df.sort_values`: trie les donn√©es par ordre croissant ou d√©croissant.\n",
    "- `df.to_dict`: convertit un DataFrame en objet Python.\n",
    "- `df.to_numpy`: convertit un DataFrame en matrice NumPy.\n",
    "\n",
    "### ‚úîÔ∏è Vu dans l'exemple 2\n",
    "\n",
    "- `pd.read_csv`: lit un fichier CSV et renvoie un DataFrame.\n",
    "- `df.groupby`: groupe les lignes d'un DataFrame par une ou des colonnes.\n",
    "- `df.agg`: sp√©cifie la m√©thode d'aggregation lors d'un groupby.\n",
    "- `df.rename`: renomme les colonnes d'un DataFrame.\n",
    "- `df.str.contains`: renvoie un masque binaire pour chaque ligne qui contient un ou plusieurs mots.\n",
    "\n",
    "### ‚úîÔ∏è Vu dans l'exemple 3\n",
    "\n",
    "- `pd.read_parquet`: lit un fichier parquet et renvoie un DataFrame.\n",
    "- `df.dropna`: retire les lignes ou colonnes qui contiennent des valeurs nulles.\n",
    "- `df.fillna`: remplace les valeurs nulles par une valeur.\n",
    "- `df.duplicated`: renvoie un masque binaire pour les lignes qui sont dupliqu√©es.\n",
    "- `df.drop_duplicates`: retire les lignes dupliqu√©es.\n",
    "- `df.set_index`: d√©finit la cl√© primaire d'un DataFrame.\n",
    "- `df.join`: joint deux DataFrames en fonction d'une cl√© commune."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
